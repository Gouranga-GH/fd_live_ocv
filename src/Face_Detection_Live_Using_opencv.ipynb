{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a28ee34",
   "metadata": {},
   "source": [
    "# Face Detection Live\n",
    "\n",
    "Let's break down the code step by step:\n",
    "\n",
    "1. **Importing Libraries**:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "```\n",
    "\n",
    "- `cv2`: This is the OpenCV library which is used for computer vision tasks such as image and video processing.\n",
    "\n",
    "2. **Loading the Pre-trained Face Detection Model**:\n",
    "\n",
    "```python\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "```\n",
    "\n",
    "- `cv2.CascadeClassifier`: This class is used to detect objects in images or video frames. We're loading a pre-trained Haar cascade classifier for detecting frontal faces. Haar cascades are a type of classifier used for object detection.\n",
    "\n",
    "3. **Starting Video Capture**:\n",
    "\n",
    "```python\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "```\n",
    "\n",
    "- `cv2.VideoCapture(0)`: This function initializes a video capture object. The argument `0` indicates that we want to capture video from the default webcam connected to the computer.\n",
    "\n",
    "4. **Main Loop for Video Processing**:\n",
    "\n",
    "```python\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "```\n",
    "\n",
    "- `video_capture.read()`: This method reads a frame from the video capture object. It returns two values: `ret`, which indicates whether a frame was successfully read, and `frame`, which is the captured frame.\n",
    "\n",
    "5. **Converting Frame to Grayscale**:\n",
    "\n",
    "```python\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "```\n",
    "\n",
    "- `cv2.cvtColor`: This function converts an image from one color space to another. In this case, we're converting the BGR (Blue-Green-Red) color image to grayscale.\n",
    "\n",
    "6. **Face Detection**:\n",
    "\n",
    "```python\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "```\n",
    "\n",
    "- `face_cascade.detectMultiScale`: This method detects objects (faces in this case) in the grayscale image. It returns a list of rectangles where faces are detected. Parameters like `scaleFactor`, `minNeighbors`, and `minSize` affect the quality and speed of detection.\n",
    "\n",
    "7. **Drawing Bounding Boxes**:\n",
    "\n",
    "```python\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "```\n",
    "\n",
    "- `cv2.rectangle`: This function draws a rectangle on the image. We draw a rectangle around each detected face. The arguments are the image (`frame`), the top-left corner coordinates (`(x, y)`), the bottom-right corner coordinates (`(x+w, y+h)`), the color of the rectangle (here, `(0, 255, 0)` for green), and the thickness of the rectangle (here, `2` pixels).\n",
    "\n",
    "8. **Displaying the Frame**:\n",
    "\n",
    "```python\n",
    "cv2.imshow('Video', frame)\n",
    "```\n",
    "\n",
    "- `cv2.imshow`: This function displays an image in a window. We display the frame with the detected faces in a window named `'Video'`.\n",
    "\n",
    "9. **Exiting the Loop**:\n",
    "\n",
    "```python\n",
    "if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    break\n",
    "```\n",
    "\n",
    "- `cv2.waitKey(1)`: This function waits for a key event for the specified milliseconds (here, `1` millisecond). If any key is pressed within this time, it returns the ASCII value of that key. If `q` key is pressed, the program breaks out of the loop and exits.\n",
    "\n",
    "10. **Releasing Resources**:\n",
    "\n",
    "```python\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "- `video_capture.release()`: This method releases the video capture object, releasing the webcam.\n",
    "- `cv2.destroyAllWindows()`: This function closes all OpenCV windows. It's important to call this function to clean up resources properly when the program exits.\n",
    "\n",
    "This code continuously captures video from the webcam, detects faces in each frame, draws bounding boxes around the detected faces, and displays the result in a window. It exits when the 'q' key is pressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1151e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the required library\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88968e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f9b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Error: Could not open video device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175249a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw a rectangle around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Exit the loop when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the video capture object and close all windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
